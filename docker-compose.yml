version: '3.8'

services:
  # Main API service
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: communitymed-api
    ports:
      - "8000:8000"
    environment:
      - USE_MOCK_AGENTS=true
      - HF_TOKEN=${HF_TOKEN}
      - PYTHONUNBUFFERED=1
    volumes:
      - ./data:/app/data
      - ./checkpoints:/app/checkpoints
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Gradio demo service
  demo:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: communitymed-demo
    command: ["python", "demo/gradio_app.py"]
    ports:
      - "7860:7860"
    environment:
      - USE_MOCK_AGENTS=true
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=7860
    volumes:
      - ./data:/app/data
      - ./checkpoints:/app/checkpoints
    restart: unless-stopped
    depends_on:
      - api

  # Optional: Redis for caching (future use)
  # redis:
  #   image: redis:alpine
  #   container_name: communitymed-redis
  #   ports:
  #     - "6379:6379"
  #   restart: unless-stopped

# GPU-enabled API service (uncomment if GPU available)
# api-gpu:
#   build:
#     context: .
#     dockerfile: Dockerfile
#   container_name: communitymed-api-gpu
#   ports:
#     - "8000:8000"
#   environment:
#     - USE_MOCK_AGENTS=false
#     - HF_TOKEN=${HF_TOKEN}
#   volumes:
#     - ./data:/app/data
#     - ./checkpoints:/app/checkpoints
#   deploy:
#     resources:
#       reservations:
#         devices:
#           - driver: nvidia
#             count: 1
#             capabilities: [gpu]
#   restart: unless-stopped

networks:
  default:
    name: communitymed-network

volumes:
  data:
  checkpoints:
  logs:
