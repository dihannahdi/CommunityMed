# ğŸ† CommunityMed AI - MedGemma Impact Challenge Submission

## ğŸŒ Project: Community Health Worker Diagnostic Assistant

**Empowering 3.5 million CHWs to provide accurate, immediate health assessments in resource-limited settings using HAI-DEF models.**

[![Main Track](https://img.shields.io/badge/Track-Main%20%2475K-gold)](https://kaggle.com/competitions/med-gemma-impact-challenge)
[![Agentic Prize](https://img.shields.io/badge/Prize-Agentic%20Workflow%20%245K-blue)](https://kaggle.com/competitions/med-gemma-impact-challenge)
[![Edge AI Prize](https://img.shields.io/badge/Prize-Edge%20AI%20%245K-green)](https://kaggle.com/competitions/med-gemma-impact-challenge)
[![Novel Task Prize](https://img.shields.io/badge/Prize-Novel%20Task%20%245K-purple)](https://kaggle.com/competitions/med-gemma-impact-challenge)

---

## ğŸ“‹ Competition Requirements Met

| Criteria | Weight | Our Solution |
|----------|--------|--------------|
| **HAI-DEF Usage** | 20% | âœ… MedGemma-4B-IT (multimodal), MedGemma-27B-text (reasoning), MedSigLIP (vision), HeAR (audio) |
| **Problem Domain** | 15% | âœ… CHW shortage in LMICs - 18M shortage per WHO; clear user journey defined |
| **Impact Potential** | 15% | âœ… 200K+ lives/year impact estimated; ROI model included |
| **Product Feasibility** | 20% | âœ… Full technical docs, fine-tuning pipeline, deployment strategy, edge quantization |
| **Execution & Communication** | 30% | âœ… 3-min video, 3-page writeup, organized codebase, live demo |

---

## ğŸ¯ Problem Statement

### The Crisis
- **18 million** global shortage of healthcare workers (WHO 2030 estimate)
- **3.5 million** Community Health Workers serve 5+ billion people
- **68%** of the world lacks access to diagnostic imaging expertise
- **Average CHW** sees 50+ patients/day with 0 diagnostic tools

### Our Solution: CommunityMed AI
An offline-capable, multimodal diagnostic assistant that:
1. **Analyzes chest X-rays** for TB, pneumonia, and 15+ conditions
2. **Processes symptom descriptions** via voice in local languages  
3. **Provides evidence-based triage recommendations**
4. **Maintains doctor-in-the-loop via async review system**

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CommunityMed AI Platform                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“± Mobile App (Flutter)                                        â”‚
â”‚  â”œâ”€â”€ Offline-first design with sync                             â”‚
â”‚  â”œâ”€â”€ Voice input (multilingual)                                 â”‚
â”‚  â””â”€â”€ Camera integration for X-rays                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¤– Agentic Workflow Layer                                      â”‚
â”‚  â”œâ”€â”€ Orchestrator Agent â†’ Routes to specialists                 â”‚
â”‚  â”œâ”€â”€ Radiology Agent â†’ MedGemma-4B-IT + MedSigLIP              â”‚
â”‚  â”œâ”€â”€ Clinical Reasoning Agent â†’ MedGemma-27B-text               â”‚
â”‚  â”œâ”€â”€ Audio Analysis Agent â†’ HeAR (lung sounds)                  â”‚
â”‚  â””â”€â”€ Triage Agent â†’ Risk stratification                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ§  HAI-DEF Model Stack                                         â”‚
â”‚  â”œâ”€â”€ MedGemma-4B-IT: Multimodal radiology analysis             â”‚
â”‚  â”œâ”€â”€ MedGemma-27B-text: Clinical reasoning & synthesis         â”‚
â”‚  â”œâ”€â”€ MedSigLIP: Medical image embeddings                       â”‚
â”‚  â”œâ”€â”€ HeAR: Lung sound analysis                                  â”‚
â”‚  â””â”€â”€ Fine-tuned LoRA adapters for TB/tropical diseases         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ’¾ Data Layer                                                  â”‚
â”‚  â”œâ”€â”€ Local SQLite for offline                                  â”‚
â”‚  â”œâ”€â”€ Redis for session caching                                 â”‚
â”‚  â””â”€â”€ PostgreSQL for sync                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
MedGemma/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ pyproject.toml                      # Modern Python package config
â”œâ”€â”€ Dockerfile                          # Container deployment
â”œâ”€â”€ docker-compose.yml                  # Multi-service orchestration
â”œâ”€â”€ LICENSE                             # MIT License
â”œâ”€â”€ .gitignore                          # Git ignore patterns
â”‚
â”œâ”€â”€ config/                             # Configuration files
â”‚   â”œâ”€â”€ model_config.yaml               # HAI-DEF model paths and settings
â”‚   â””â”€â”€ training_config.yaml            # QLoRA fine-tuning hyperparameters
â”‚
â”œâ”€â”€ src/                                # Source code
â”‚   â”œâ”€â”€ models/                         # Model implementations
â”‚   â”‚   â”œâ”€â”€ medgemma_loader.py          # ğŸŒŸ MedGemma 1.5/4B/27B with quantization
â”‚   â”‚   â”œâ”€â”€ hear_loader.py              # ğŸ¤ HeAR audio embeddings (Novel Task)
â”‚   â”‚   â”œâ”€â”€ medsiglip_loader.py         # ğŸ–¼ï¸ MedSigLIP image embeddings
â”‚   â”‚   â””â”€â”€ fine_tuning.py              # QLoRA fine-tuning pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                         # Agentic workflow (Prize Target!)
â”‚   â”‚   â”œâ”€â”€ orchestrator.py             # Multi-agent routing
â”‚   â”‚   â”œâ”€â”€ radiology_agent.py          # X-ray analysis (MedGemma-4B)
â”‚   â”‚   â”œâ”€â”€ clinical_agent.py           # Clinical reasoning (MedGemma-27B)
â”‚   â”‚   â”œâ”€â”€ audio_agent.py              # Cough analysis (HeAR)
â”‚   â”‚   â””â”€â”€ triage_agent.py             # Risk stratification
â”‚   â”‚
â”‚   â”œâ”€â”€ demo/                           # Interactive demos
â”‚   â”‚   â””â”€â”€ gradio_app.py               # ğŸ¯ Live Gradio demo app
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                            # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ main.py                     # Application entry
â”‚   â”‚   â”œâ”€â”€ routes.py                   # REST endpoints
â”‚   â”‚   â””â”€â”€ schemas.py                  # Pydantic schemas
â”‚   â”‚
â”‚   â””â”€â”€ utils/                          # Utilities
â”‚       â””â”€â”€ impact_calculator.py        # WHO-based impact metrics
â”‚
â”œâ”€â”€ examples/                           # Usage examples
â”‚   â””â”€â”€ tb_screening_demo.py            # ğŸ¥ End-to-end TB screening
â”‚
â”œâ”€â”€ scripts/                            # Utility scripts
â”‚   â”œâ”€â”€ benchmark.py                    # âš¡ Performance benchmarking
â”‚   â”œâ”€â”€ train.py                        # Training script
â”‚   â””â”€â”€ evaluate.py                     # Evaluation script
â”‚
â”œâ”€â”€ submission/                         # Kaggle submission materials
â”‚   â”œâ”€â”€ writeup.md                      # 3-page writeup (competition template)
â”‚   â”œâ”€â”€ video_script.md                 # 3-min video script
â”‚   â””â”€â”€ impact_analysis.md              # WHO-cited impact model
â”‚
â”œâ”€â”€ tests/                              # Unit tests
â”‚   â”œâ”€â”€ test_models.py                  # Model loading tests
â”‚   â”œâ”€â”€ test_haidef_models.py           # HeAR/MedSigLIP tests
â”‚   â””â”€â”€ test_api.py                     # API endpoint tests
â”‚
â””â”€â”€ notebooks/                          # Jupyter notebooks
    â”œâ”€â”€ 01_data_exploration.ipynb
    â”œâ”€â”€ 02_fine_tuning.ipynb
    â””â”€â”€ 03_evaluation.ipynb
```

---

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone repository
git clone https://github.com/dihannahdi/communitymed-ai.git
cd communitymed-ai

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure HuggingFace Access

```bash
# Login to HuggingFace (requires token with model access)
huggingface-cli login
```

### 3. Run the Demo (No GPU Required)

```bash
# Run end-to-end TB screening demo (mock mode)
python examples/tb_screening_demo.py

# Launch interactive Gradio demo
python -m src.demo.gradio_app
```

### 4. Run Benchmarks (GPU Recommended)

```bash
# Benchmark HAI-DEF models
python scripts/benchmark.py --model hear --samples 100
python scripts/benchmark.py --model medsiglip --samples 100

# Full MedGemma benchmark (requires GPU)
python scripts/benchmark.py --model medgemma-4b-it --samples 50
```

### 5. Start API Server

```bash
# Start FastAPI server
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

### 6. Fine-tune Models (Optional)

```bash
# Download datasets
python scripts/download_datasets.py

# Fine-tune MedGemma with QLoRA
python scripts/train.py --config config/training_config.yaml
```

---

## ğŸ“Š Impact Metrics

*Evidence-based methodology using WHO data - see [submission/impact_analysis.md](submission/impact_analysis.md)*

| Metric | Year 1 (Pilot) | Year 3 (Scale) | Source |
|--------|---------------|----------------|--------|
| **CHWs Empowered** | 10,000 | 200,000 | Deployment plan |
| **Patients Screened** | 62.5M | 1.25B | 25 patients/CHW/day |
| **TB Cases Detected** | 159,000 | 3.2M | 17% prevalence |
| **Lives Saved** | **9,500** | **195,000** | WHO mortality data |
| **Cost per Life Saved** | $246 | $128 | Full ROI model |
| **ROI** | 2,458% | 9,831% | Cost-benefit analysis |

---

## ğŸ› ï¸ Technical Details

### HAI-DEF Models Used

| Model | Parameters | Task | Prize Target |
|-------|------------|------|--------------|
| **MedGemma-1.5-4B-IT** | 4.3B | Multimodal radiology | Main Track |
| **MedGemma-27B-text-IT** | 27B | Clinical reasoning | Main Track |
| **HeAR** | 768-dim | Cough audio analysis | Novel Task ($10K) |
| **MedSigLIP** | 1.2B | Zero-shot image classification | Edge AI |

### Fine-tuning Configuration

- **Method**: QLoRA (4-bit quantization)
- **Rank**: 16
- **Alpha**: 16
- **Epochs**: 3
- **Learning Rate**: 2e-4
- **Batch Size**: 4 (with gradient accumulation 4)

### Edge Deployment

- **Quantization**: GPTQ 4-bit â†’ GGUF
- **Target Device**: Android 10+, 6GB RAM
- **Model Size**: ~2GB (MedGemma-4B quantized)
- **Inference Time**: <2s on Snapdragon 865

---

## ğŸ“„ License

This project is licensed under CC BY 4.0 as required by the competition.

---

## ğŸ‘¥ Team

- **[Your Name]** - Lead Developer & ML Engineer
- **Role**: Fine-tuning, deployment, agentic workflow

---

## ğŸ”— Links

- **Video Demo**: [YouTube/Loom link]
- **Live Demo**: [HuggingFace Spaces link]
- **Model**: [HuggingFace Model link]
- **Kaggle Writeup**: [Writeup link]

---

## ğŸ“š References

1. Google MedGemma Technical Report (2025)
2. WHO Community Health Worker Guidelines
3. HAI-DEF Developer Documentation
4. Kaggle MedGemma Impact Challenge Rules
